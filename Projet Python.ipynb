{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2be90c-3fd3-42e3-9f91-478973ed61cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54a7996-32cf-4f1a-9746-b3bd90d72e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia-api\n",
      "  Using cached Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\charles\\anaconda3\\lib\\site-packages (from wikipedia-api) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2021.10.8)\n",
      "Building wheels for collected packages: wikipedia-api\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13475 sha256=6720b1597ce67bbc58310035def72e306a272bcb4e78245f223d9c53e018d3ca\n",
      "  Stored in directory: c:\\users\\charles\\appdata\\local\\pip\\cache\\wheels\\c7\\cf\\1a\\c300428dd51654cdadc921abdff75acaa7cc80b7151a2f0695\n",
      "Successfully built wikipedia-api\n",
      "Installing collected packages: wikipedia-api\n",
      "Successfully installed wikipedia-api-0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvis\n",
      "  Using cached pyvis-0.3.1.tar.gz (748 kB)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from pyvis) (2.11.3)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from pyvis) (2.6.3)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from pyvis) (7.29.0)\n",
      "Collecting jsonpickle>=1.4.1\n",
      "  Downloading jsonpickle-3.0.0-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (58.0.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (3.0.20)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.1.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.18.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\charles\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (2.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (1.1.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\charles\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.5)\n",
      "Building wheels for collected packages: pyvis\n",
      "  Building wheel for pyvis (setup.py): started\n",
      "  Building wheel for pyvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyvis: filename=pyvis-0.3.1-py3-none-any.whl size=755850 sha256=453521c5ce8d8d219bf66ab4c7afd9c70646bf7dd9dfac5834892d0bf6ce7c4e\n",
      "  Stored in directory: c:\\users\\charles\\appdata\\local\\pip\\cache\\wheels\\55\\7b\\4b\\dc896cf96ad07e0dc92d30e1984ab583c0d0feec208756e2b2\n",
      "Successfully built pyvis\n",
      "Installing collected packages: jsonpickle, pyvis\n",
      "Successfully installed jsonpickle-3.0.0 pyvis-0.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\charles\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eventlet\n",
      "  Downloading eventlet-0.33.2-py2.py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: greenlet>=0.3 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from eventlet) (1.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\charles\\anaconda3\\lib\\site-packages (from eventlet) (1.16.0)\n",
      "Collecting dnspython>=1.15.0\n",
      "  Using cached dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
      "Installing collected packages: dnspython, eventlet\n",
      "Successfully installed dnspython-2.2.1 eventlet-0.33.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia-api\n",
    "!pip install pyvis\n",
    "!pip install eventlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ac9961-afdb-4043-85c7-5e80ac8795a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723ab0d-efb3-46e9-a1ba-74fead7f5302",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création d'une fonction qui recherche les pages voisines d'une page wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd1e90c-ab75-44c2-8a0a-0b67caf6c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne considère que le Wikipedia en français\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\"fr\", extract_format=wikipediaapi.ExtractFormat.WIKI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e64f9e-b244-4ad8-950f-ccab7ddcf8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va commencer par écrire une fonction qui retourne la liste des voisins d'une page donnée\n",
    "\n",
    "def get_neighbors(name):\n",
    "    \n",
    "    page = wiki_wiki.page(name)\n",
    "    return list(page.links.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f687d27-ca5a-4309-a5a0-3d38e48df843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On doit ensuite trouver les voisins des voisins, les ajouter dans une pile de pages à parcourir, puis trouver leurs voisins et recommencer, \n",
    "# et ainsi de suite jusqu'à ce que la pile soit vide (l'élément d'indice 0 est le fond de la pile)\n",
    "# On parle alors de parcours en profondeur du graphe (qu'on peut voir comme un arbre ici)\n",
    "# On va représenter le graphe sous forme d'un dictionnaire d'adjacence, de la forme {\"sommet\" : [voisins]}\n",
    "\n",
    "# Première version pour évaluer le type des liens présents dans des pages quelconques :\n",
    "\n",
    "def get_tree(start):\n",
    "    i = 0\n",
    "    pile = [start]\n",
    "    tree = {}\n",
    "    while pile != [] and i < 50:\n",
    "        node = pile.pop()\n",
    "        i += 1\n",
    "        print(node) # On va visualiser les noms de pages qu'on traite\n",
    "        tree[node] = []\n",
    "        for neighbor in get_neighbors(node):\n",
    "            tree[node].append(neighbor)\n",
    "            if neighbor not in tree.keys():\n",
    "                pile.append(neighbor)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0746eb7-f8ac-4711-8db8-cd7f6746bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait un appel à la fonction get_tree pour regarder ce qu'il se passe\n",
    "\n",
    "get_tree(\"Python_(langage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ce2281-d66d-42e9-aa7d-7fb2d461733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problème : On voit qu'il y a beaucoup de liens qui mènent vers des pages \"indésirables\", comme les modèles, \n",
    "# les discussions, les aides etc\n",
    "\n",
    "# On va donc réaliser un filtrage d'expression régulière sur le nom des pages, à l'aide du module re :\n",
    "\n",
    "import re\n",
    "\n",
    "def filtering(name):\n",
    "    if re.match(r\"Portail:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion Projet:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Module:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Projet:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Modèle:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Aide:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Catégorie:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Utilisateur:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Utilisatrice:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion Utilisateur:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Sujet:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Référence:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion Wikipédia:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Fichier:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion modèle:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion Portail:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion catégorie:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Wikipédia:.*\", name):\n",
    "        return False\n",
    "    if re.match(r\"Discussion utilisateur:.*\", name):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d8609-3ad0-4e41-9795-7496a1f3632c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fonction d'appel API pour récupérer des pages wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9421071b-3a1a-4502-b797-cc1eb37b484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rajoute une ligne dans la fonction :\n",
    "\n",
    "import numpy as np # On a besoin des fonction numpy sur les tableaux\n",
    "\n",
    "def get_10000_nodes(pile, tree):\n",
    "    i = 0\n",
    "    while pile != [] and i<10000:\n",
    "        global node\n",
    "        node = pile.pop()\n",
    "        if node not in tree.keys():\n",
    "            # print(node)\n",
    "            tree[node] = [[]]\n",
    "            i += 1\n",
    "            neighbors = get_neighbors(node)\n",
    "            if len(neighbors)>0:\n",
    "                for neighbor in neighbors:\n",
    "                    if filtering(neighbor) and len(neighbor)>1:\n",
    "                        tree[node].append(neighbor)\n",
    "                        if neighbor not in tree.keys():\n",
    "                            pile.append(neighbor)\n",
    "    return list(np.unique(np.array(pile))), tree\n",
    "import requests\n",
    "import eventlet # Pour réduire la possibilité de timeout à la lecture\n",
    "\n",
    "global pile, tree # Pour pouvoir garder la progression en cas d'erreur, seule la page d'erreur est perdue, ce n'est pas très grave\n",
    "\n",
    "def get_tree_clean(start = \"Python_(langage)\", pile = [], tree = {}): #On cherche tout le réseau de pages, en partant de la page de Python\n",
    "    j = 0 # Simple compteur pour savoir la vitesse approximative en exécution\n",
    "    with eventlet.Timeout(40000): #Pour empêcher les timeouts\n",
    "        while pile != []: # On traite tous les sommets possibles\n",
    "            pile, tree = get_10000_nodes(pile, tree) # On actualise la valeur toutes les 10 000 pages \n",
    "            j += 1\n",
    "            print(j)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3fb00-2869-46a1-9d02-a58e70446621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualisation du réseau de pages Wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f0fac23-ba12-4923-9da2-25d5b8ac2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour visualiser le réseau des pages Wikipédia, on va devoir transformer le dictionnaire d'adjacence en dataframe pandas\n",
    "# Le dataframe comporte 4 colonnes : \"Source\", \"Target\", \"Type\" et \"Weight\"\n",
    "# Le graphe étant orienté, le type d'arête est \"Directed\"\n",
    "\n",
    "def create_dataframe(tree, nb_nodes):\n",
    "    data = {\"Source\" : [], \"Target\" : [], \"Size\" : [], \"Weight\" : []}\n",
    "    i = 0\n",
    "    for node in tree.keys():\n",
    "        i+=1\n",
    "        if i == nb_nodes:\n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            for neighbor in tree[node]:\n",
    "                if neighbor in tree.keys():\n",
    "                    weight = len(tree[neighbor])\n",
    "                else:\n",
    "                    weight = 0\n",
    "                data[\"Source\"].append(node)\n",
    "                data[\"Target\"].append(neighbor)\n",
    "                data[\"Size\"].append(len(tree[node]))\n",
    "                data[\"Weight\"].append(weight)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe984b58-e08f-43e4-88a5-d14591c88337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On visualise alors le graphe, en utilisant le module PyVis :\n",
    "\n",
    "from pyvis.network import Network\n",
    "\n",
    "def visualize(data, c):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook = True)\n",
    "    net.barnes_hut()\n",
    "    sources = data[\"Source\"]\n",
    "    targets = data[\"Target\"]\n",
    "    weights = data[\"Weight\"]\n",
    "    sizes = data[\"Size\"]\n",
    "\n",
    "    edge_data = zip(sources, targets, weights, sizes)\n",
    "\n",
    "    for e in edge_data:\n",
    "        src = e[0]\n",
    "        dst = e[1]\n",
    "        w = e[2]\n",
    "        sz = e[3]\n",
    "\n",
    "        net.add_node(src, src, size = sz/10, title = src)\n",
    "        net.add_node(dst, dst, size = w/10, stitle = dst)\n",
    "        net.add_edge(src, dst, value = w**2)\n",
    "    for i in range(len(c)-1):\n",
    "        src = c[i]\n",
    "        dst = c[i+1]\n",
    "        net.add_node(src, src, size = 400, title = src)\n",
    "        net.add_node(dst, dst, size = 400, title = dst)\n",
    "        net.add_edge(src, dst, width = 4000, color = \"red\" )\n",
    "    net.show(\"Wiki_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498aef96-6455-4886-aecd-436d38eec1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = pd.read_pickle(\"https://minio.lab.sspcloud.fr/cheitz/tree.pickle\") # On charge la base de données enregistrée au format pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a7b0757c-4834-4f80-aaa4-991904dbd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataframe(tree, 100000) # On ne crée que les 100 000 premières arêtes, pour des raisons de stockage mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9909f225-8a79-44f4-8899-ed452e41c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[:50000] # On se limite à un plus petit nombre d'arêtes pour pouvoir visualiser le graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6da09681-3057-4fd8-9998-e1d296ae1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    }
   ],
   "source": [
    "visualize(data2, []) # On crée le fichier HTML qui code le graphe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382cc86-fd53-498a-940f-ec687c50f3e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Insertion de l'algorithme de Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42dbbaa-0a7c-4d90-bc1a-83d6a2711c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(tree, deb): # Fonction d'initialisation de l'algorithme de Dijkstra\n",
    "    d = {} # Dictionnaire de la forme {\"sommet\" : (distance au sommet de départ, prédecesseur dans le chemin vers le sommet d'arrivée)}\n",
    "    sommets = list(tree.keys())\n",
    "    for v in tree.values():\n",
    "        sommets += v\n",
    "    sommets = list(np.unique(sommets))\n",
    "    for s in sommets:\n",
    "        d[s] = (np.inf, None)\n",
    "    d[deb] = (0, None)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b72809c-2651-4b2e-b82f-d2ca8f0d80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(d, Q): # Fonction pour trouver le sommet de distance minimale au sommet de départ dans un sous-graphe Q du graphe de départ\n",
    "    mini = np.inf\n",
    "    sommet = None\n",
    "    for s in Q.keys():\n",
    "        if d[s][0]<mini:\n",
    "            mini = d[s][0]\n",
    "            sommet = s\n",
    "    return sommet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214e4018-c3b9-43b4-8a54-e44bd9e6e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maj_distances(d, s1, s2): # Fonction de mise à jour des distances pour 2 sommets donnés\n",
    "    if d[s2][0]>d[s1][0]+1:\n",
    "        d[s2] = (d[s1][0]+1,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354eb8ac-dd66-47e3-8741-a96ec4c1c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra(tree, deb, fin): # Algorithme de Dijkstra\n",
    "    d = initialize(tree, deb)\n",
    "    Q = tree.copy()\n",
    "    s1 = None\n",
    "    while Q!={} and s1!=fin:\n",
    "        s1 = find_min(d, Q)\n",
    "        if s1 == None:\n",
    "            return None\n",
    "        Q.pop(s1)\n",
    "        for s2 in tree[s1]:\n",
    "            if s2 in d.keys():\n",
    "                maj_distances(d, s1, s2)\n",
    "    return d # On renvoie le dictionnaire {\"sommet\" : (distance, prédecesseur)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c6217f-1a36-4044-8947-b7122adadf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chemin(tree, deb, fin): # Fonction qui permet de récupérer le chemin le plus court entre le départ et l'arrivée\n",
    "    d = dijkstra(tree, deb, fin)\n",
    "    if d == None:\n",
    "        print(\"Pas de chemin trouvé entre vos 2 sommets :( \")\n",
    "        pass\n",
    "    else:\n",
    "        A = []\n",
    "        s = fin\n",
    "        while s!=deb:\n",
    "            A = [s]+A\n",
    "            s = d[s][1]\n",
    "        return [deb]+A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d154d786-58e2-4555-ae64-5bd4b3318d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605470"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(tree.keys()) # On prend la liste de tous les sommets du graphe\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef3719",
   "metadata": {},
   "source": [
    "### Attention, le choix de 10 000 sommets est arbitraire, et correspond aux caractéristiques de mon ordinateur !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ae6eb0-0013-4dd9-8a41-7e805ee6c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes[:10000] # On doit se limiter aux 10 000 premiers sommets pour des raisons de tractabilité \n",
    "tree_10k = {k : tree[k] for k in nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfeabfdc-676f-4f17-9933-2a5de6ba8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Óscar Iván Zuluaga Élections législatives cubaines de 1956\n"
     ]
    }
   ],
   "source": [
    "deb, fin = np.random.choice(nodes), np.random.choice(nodes) # On choisit un début et une fin aléatoirement\n",
    "print(deb, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e577418-d2b5-4180-93a9-d307846d12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Óscar Iván Zuluaga', 'Équateur (pays)', \"État d'exception\", \"État d'urgence en France\", 'Élection présidentielle française de 2017', 'Élections législatives et présidentielles dans le monde', 'Élections législatives cubaines de 2018', 'Élections législatives cubaines de 1956']\n"
     ]
    }
   ],
   "source": [
    "c = chemin(tree_10k, deb, fin) # On regarde quel est le chemin le plus court entre deb et fin\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20679cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_10k = list(tree_10k.keys())\n",
    "subgraph = []\n",
    "while not all(i in subgraph for i in c):\n",
    "    subgraph = np.random.choice(nodes_10k, 20000)\n",
    "subtree = {k : tree_10k[k] for k in nodes_10k}\n",
    "subdata = create_dataframe(subtree, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    }
   ],
   "source": [
    "visualize(subdata, c) # On visualise le chemin qu'on a obtenu de la façon suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bbd542",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3eda79c-a1ba-4431-af7f-6676ea2e686b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Création d'une interface graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e1b32-30e8-4559-8cc6-52b8ee275ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'interface graphique\n",
    "from tkinter import *\n",
    "import tkinter.font as font\n",
    "\n",
    "#Création de la fenêtre et de son titre\n",
    "fenêtre=Tk()\n",
    "fenêtre.title(\"Plus court chemin Wikipedia\")\n",
    "fenêtre.config(bg = \"blue\") #couleur de l'arrière-plan\n",
    "fenêtre.geometry(\"800x600\") #dimensions de la fenêtre\n",
    "\n",
    "\n",
    "#Création d'un label pour la saisie des sommets à relier\n",
    "SommetLabel = Label(fenêtre, text=\"Saisir les pages wikipedia de départ et d'arrivée : \", bg = \"blue\", fg='white')\n",
    "SommetLabel['font'] = font.Font(family='Times New Roman', size=18, weight=\"bold\")\n",
    "SommetLabel.pack(pady=10)\n",
    "    \n",
    "    \n",
    "#Création des zones de saisie\n",
    "sommet1 = StringVar()\n",
    "sommet2 = StringVar()\n",
    "\n",
    "sommet1.set(\"page de départ, ex : Python(langage)\")\n",
    "sommet2.set(\"page d'arrivée, ex : Chocolat\")\n",
    "\n",
    "saisieSommet1 = Entry(fenêtre, textvariable=sommet1, width=35)\n",
    "saisieSommet2 = Entry(fenêtre, textvariable=sommet2, width=35)\n",
    "\n",
    "saisieSommet1['font'] = font.Font(family='Times New Roman', size=15)\n",
    "saisieSommet2['font'] = font.Font(family='Times New Roman', size=15)\n",
    "\n",
    "saisieSommet1.pack(pady=10)\n",
    "saisieSommet2.pack(pady=5)\n",
    "\n",
    "#Récupération des entrées\n",
    "départ = saisieSommet1.get()\n",
    "arrivée = saisieSommet2.get()\n",
    "\n",
    "\n",
    "#Création d'un bouton\n",
    "bouton1 = Button(fenêtre, text=\"CALCULER CHEMIN\", relief=GROOVE, width=17, height=1, bg=\"yellow\", command=chemin(tree_100k, départ, arrivée)) \n",
    "bouton1['font'] = font.Font(family='Times New Roman', size=15, weight=\"bold\")\n",
    "bouton1.pack(pady=20)\n",
    "\n",
    "\n",
    "#Label pour afficher le résultat\n",
    "ResultatLabel = Label(fenêtre, text=\"Le plus court chemin est : \", bg = \"blue\", fg='white')\n",
    "ResultatLabel['font'] = font.Font(family='Times New Roman', size=18, weight=\"bold\")\n",
    "ResultatLabel.pack(pady=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
